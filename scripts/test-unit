#!/bin/bash

# Mini RAG Unit Testing Script
# This script runs Python unit tests using pytest
# and generates comprehensive test reports

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
REPORTS_DIR="test-reports"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
REPORT_PREFIX="mini-rag-unit-test"
COVERAGE_DIR="coverage-reports"
PYTEST_ARGS=""

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "${PURPLE}[HEADER]${NC} $1"
}

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to show help
show_help() {
    echo -e "${CYAN}Mini RAG Unit Testing Script${NC}"
    echo ""
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  -h, --help              Show this help message"
    echo "  -v, --verbose           Run tests in verbose mode"
    echo "  -c, --coverage          Run tests with coverage report"
    echo "  -f, --fast              Run tests in fast mode (no coverage, minimal output)"
    echo "  -k, --keyword KEYWORD   Run tests matching keyword"
    echo "  -m, --marker MARKER     Run tests with specific marker"
    echo "  -x, --stop-on-fail      Stop on first failure"
    echo "  --install-deps          Install required dependencies"
    echo "  --clean                 Clean test reports and cache"
    echo "  --parallel              Run tests in parallel"
    echo "  --html                  Generate HTML coverage report"
    echo "  --xml                   Generate XML test report"
    echo "  --skip-deps             Skip dependency checks (faster)"
    echo "  --streaming             Run only streaming-related tests"
    echo "  --regression            Run only regression tests"
    echo ""
    echo "Examples:"
    echo "  $0                      # Run all tests with dependency checks"
    echo "  $0 -c --html            # Run with coverage and HTML report"
    echo "  $0 -k auth              # Run only auth-related tests"
    echo "  $0 -m slow              # Run only slow tests"
    echo "  $0 --streaming          # Run only streaming tests"
    echo "  $0 --regression         # Run only regression tests"
    echo "  $0 --parallel           # Run tests in parallel"
    echo "  $0 --skip-deps          # Skip dependency checks for faster runs"
    echo "  $0 --install-deps       # Install all dependencies"
    echo ""
}

# Function to check and install project dependencies
check_project_dependencies() {
    print_status "Checking project dependencies..."
    
    # Check if requirements.txt exists
    if [ ! -f "requirements.txt" ]; then
        print_warning "requirements.txt not found. Skipping project dependency check."
        return 0
    fi
    
    # Check if pip is available
    if ! command_exists pip && ! command_exists pip3; then
        print_error "pip is not installed. Please install pip first."
        exit 1
    fi
    
    # Use pip3 if available, otherwise pip
    PIP_CMD="pip3"
    if ! command_exists pip3; then
        PIP_CMD="pip"
    fi
    
    # Check if virtual environment is active
    if [ -n "$VIRTUAL_ENV" ]; then
        print_success "Virtual environment detected: $VIRTUAL_ENV"
    else
        print_warning "No virtual environment detected. Consider using one for better dependency isolation."
    fi
    
    # Check critical dependencies
    local missing_deps=()
    # Check each dependency with its correct import name
    local deps_to_check=(
        "numpy:numpy"
        "fastapi:fastapi"
        "uvicorn:uvicorn"
        "qdrant-client:qdrant_client"
        "passlib:passlib"
        "PyJWT:jwt"
        "requests:requests"
        "pypdf:pypdf"
    )
    
    for dep_pair in "${deps_to_check[@]}"; do
        local pkg_name="${dep_pair%%:*}"
        local import_name="${dep_pair##*:}"
        if ! $PYTHON_CMD -c "import $import_name" 2>/dev/null; then
            missing_deps+=("$pkg_name")
        fi
    done
    
    if [ ${#missing_deps[@]} -gt 0 ]; then
        print_warning "Missing critical dependencies: ${missing_deps[*]}"
        print_status "Installing project dependencies from requirements.txt..."
        
        if $PIP_CMD install -r requirements.txt; then
            print_success "Project dependencies installed successfully"
        else
            print_error "Failed to install project dependencies"
            print_status "Attempting to install missing packages individually..."
            
            for dep in "${missing_deps[@]}"; do
                print_status "Installing $dep..."
                if $PIP_CMD install "$dep"; then
                    print_success "Installed $dep"
                else
                    print_error "Failed to install $dep"
                fi
            done
        fi
    else
        print_success "All critical project dependencies are available"
    fi
}

# Function to install testing dependencies
install_testing_dependencies() {
    print_status "Installing Python testing dependencies..."
    
    # Check if pip is available
    if ! command_exists pip && ! command_exists pip3; then
        print_error "pip is not installed. Please install pip first."
        exit 1
    fi
    
    # Use pip3 if available, otherwise pip
    PIP_CMD="pip3"
    if ! command_exists pip3; then
        PIP_CMD="pip"
    fi
    
    # Install pytest and related packages
    local testing_deps=(
        "pytest"
        "pytest-cov"
        "pytest-html"
        "pytest-xdist"
        "pytest-mock"
        "pytest-asyncio"
        "pytest-timeout"
        "pytest-benchmark"
    )
    
    print_status "Installing testing dependencies: ${testing_deps[*]}"
    $PIP_CMD install "${testing_deps[@]}"
    
    print_success "Testing dependencies installed successfully"
}

# Function to install all dependencies
install_dependencies() {
    print_header "Dependency Management"
    echo -e "${CYAN}╔══════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${CYAN}║                Installing Dependencies                      ║${NC}"
    echo -e "${CYAN}╚══════════════════════════════════════════════════════════════╝${NC}"
    
    # Install project dependencies first
    check_project_dependencies
    
    # Install testing dependencies
    install_testing_dependencies
    
    print_success "All dependencies installed successfully"
}

# Function to clean test artifacts
clean_artifacts() {
    print_status "Cleaning test artifacts..."
    
    # Remove test reports
    if [ -d "$REPORTS_DIR" ]; then
        rm -rf "$REPORTS_DIR"
        print_success "Removed test reports directory"
    fi
    
    # Remove coverage reports
    if [ -d "$COVERAGE_DIR" ]; then
        rm -rf "$COVERAGE_DIR"
        print_success "Removed coverage reports directory"
    fi
    
    # Remove Python cache
    find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
    find . -name "*.pyc" -delete 2>/dev/null || true
    find . -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true
    
    print_success "Test artifacts cleaned"
}

# Function to check Python environment
check_python_environment() {
    print_status "Checking Python environment..."
    
    # Check Python version
    if command_exists python3; then
        PYTHON_CMD="python3"
    elif command_exists python; then
        PYTHON_CMD="python"
    else
        print_error "Python is not installed or not in PATH"
        exit 1
    fi
    
    # Check Python version
    PYTHON_VERSION=$($PYTHON_CMD --version 2>&1 | cut -d' ' -f2)
    print_success "Python version: $PYTHON_VERSION"
    
    # Check Python version compatibility (3.8+)
    local python_major=$(echo $PYTHON_VERSION | cut -d'.' -f1)
    local python_minor=$(echo $PYTHON_VERSION | cut -d'.' -f2)
    
    if [ "$python_major" -lt 3 ] || ([ "$python_major" -eq 3 ] && [ "$python_minor" -lt 8 ]); then
        print_error "Python 3.8+ is required. Current version: $PYTHON_VERSION"
        exit 1
    fi
    
    print_success "Python version is compatible"
}

# Function to check and install all dependencies
check_and_install_dependencies() {
    print_header "Dependency Management"
    echo -e "${CYAN}╔══════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${CYAN}║                Checking Dependencies                        ║${NC}"
    echo -e "${CYAN}╚══════════════════════════════════════════════════════════════╝${NC}"
    
    # Check project dependencies
    check_project_dependencies
    
    # Check if pytest is installed
    if ! $PYTHON_CMD -m pytest --version >/dev/null 2>&1; then
        print_warning "pytest is not installed"
        print_status "Installing testing dependencies..."
        install_testing_dependencies
    else
        print_success "Testing framework (pytest) is available"
    fi
    
    # Final verification
    print_status "Verifying all dependencies..."
    local all_good=true
    
    # Check critical project dependencies
    local critical_deps=(
        "numpy:numpy"
        "fastapi:fastapi"
        "uvicorn:uvicorn"
        "qdrant-client:qdrant_client"
        "passlib:passlib"
        "PyJWT:jwt"
        "requests:requests"
        "pypdf:pypdf"
    )
    
    for dep_pair in "${critical_deps[@]}"; do
        local pkg_name="${dep_pair%%:*}"
        local import_name="${dep_pair##*:}"
        if ! $PYTHON_CMD -c "import $import_name" 2>/dev/null; then
            print_error "Critical dependency missing: $pkg_name (import: $import_name)"
            all_good=false
        fi
    done
    
    # Check testing dependencies
    local testing_deps=(
        "pytest:pytest"
        "pytest-cov:pytest_cov"
        "pytest-html:pytest_html"
        "pytest-xdist:xdist"
        "pytest-mock:pytest_mock"
        "pytest-asyncio:pytest_asyncio"
    )
    
    for dep_pair in "${testing_deps[@]}"; do
        local pkg_name="${dep_pair%%:*}"
        local import_name="${dep_pair##*:}"
        if ! $PYTHON_CMD -c "import $import_name" 2>/dev/null; then
            print_error "Testing dependency missing: $pkg_name (import: $import_name)"
            all_good=false
        fi
    done
    
    if [ "$all_good" = true ]; then
        print_success "All dependencies are available and ready"
    else
        print_error "Some dependencies are missing. Please run with --install-deps to fix."
        exit 1
    fi
}

# Function to confirm action
confirm() {
    read -p "$1 (y/N): " -n 1 -r
    echo
    [[ $REPLY =~ ^[Yy]$ ]]
}

# Function to run unit tests
run_unit_tests() {
    local test_suite=$1
    local additional_args=$2
    
    print_header "Running unit tests: $test_suite"
    
    # Create reports directory
    mkdir -p "$REPORTS_DIR"
    mkdir -p "$COVERAGE_DIR"
    
    # Define report file names
    local html_report="$REPORTS_DIR/${REPORT_PREFIX}_${test_suite}_${TIMESTAMP}.html"
    local xml_report="$REPORTS_DIR/${REPORT_PREFIX}_${test_suite}_${TIMESTAMP}.xml"
    local coverage_report="$COVERAGE_DIR/coverage_${test_suite}_${TIMESTAMP}"
    
    # Build pytest command
    local pytest_cmd="$PYTHON_CMD -m pytest"
    
    # Add test path
    if [ "$test_suite" = "all" ]; then
        pytest_cmd="$pytest_cmd tests/"
    elif [ "$test_suite" = "streaming" ]; then
        pytest_cmd="$pytest_cmd tests/unit/api/test_streaming_endpoints.py tests/unit/core/test_streaming_utils.py"
    elif [ "$test_suite" = "regression" ]; then
        pytest_cmd="$pytest_cmd tests/unit/api/test_streaming_endpoints.py::TestStreamingRegressionTests"
    # If keyword_/marker_ suite names are used, run against full tests/ tree
    elif [[ "$test_suite" == keyword_* ]] || [[ "$test_suite" == marker_* ]]; then
        pytest_cmd="$pytest_cmd tests/"
    else
        pytest_cmd="$pytest_cmd tests/test_${test_suite}.py"
    fi
    
    # Sanitize standalone flags in PYTEST_ARGS that require values
    local SAFE_PYTEST_ARGS="$PYTEST_ARGS"
    # Remove bare --html and --junitxml (we'll add concrete paths below)
    SAFE_PYTEST_ARGS="${SAFE_PYTEST_ARGS// --html/}"
    SAFE_PYTEST_ARGS="${SAFE_PYTEST_ARGS//--html /}"
    SAFE_PYTEST_ARGS="${SAFE_PYTEST_ARGS// --junitxml/}"
    SAFE_PYTEST_ARGS="${SAFE_PYTEST_ARGS//--junitxml /}"
    
    # Add common arguments
    pytest_cmd="$pytest_cmd $SAFE_PYTEST_ARGS"
    
    # Add additional arguments
    if [ -n "$additional_args" ]; then
        pytest_cmd="$pytest_cmd $additional_args"
    fi
    
    # Add coverage if requested
    if [[ "$PYTEST_ARGS" == *"--cov"* ]]; then
        pytest_cmd="$pytest_cmd --cov-report=html:$coverage_report --cov-report=xml:$coverage_report.xml"
    fi
    
    # Add HTML report if requested
    if [[ "$PYTEST_ARGS" == *"--html"* ]]; then
        pytest_cmd="$pytest_cmd --html=$html_report --self-contained-html"
    fi
    
    # Add XML report if requested
    if [[ "$PYTEST_ARGS" == *"--junitxml"* ]]; then
        pytest_cmd="$pytest_cmd --junitxml=$xml_report"
    fi
    
    print_status "Executing: $pytest_cmd"
    echo ""
    
    # Run the tests
    local exit_code=0
    if eval $pytest_cmd; then
        print_success "$test_suite tests completed successfully"
        exit_code=0
    else
        print_error "$test_suite tests failed"
        exit_code=1
    fi
    
    # Show report locations
    if [ -f "$html_report" ]; then
        print_success "HTML report generated: $html_report"
    fi
    
    if [ -f "$xml_report" ]; then
        print_success "XML report generated: $xml_report"
    fi
    
    if [ -d "$coverage_report" ]; then
        print_success "Coverage report generated: $coverage_report/index.html"
    fi
    
    return $exit_code
}

# Function to generate test summary
generate_summary() {
    print_header "Test Summary"
    
    # Count test files
    local test_files=$(find tests/ -name "test_*.py" 2>/dev/null | wc -l)
    local root_test_files=$(find . -maxdepth 1 -name "test_*.py" 2>/dev/null | wc -l)
    local total_test_files=$((test_files + root_test_files))
    
    # Count streaming test files specifically
    local streaming_test_files=$(find tests/ -name "*streaming*" 2>/dev/null | wc -l)
    
    echo -e "${CYAN}╔══════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${CYAN}║                    Unit Test Summary                        ║${NC}"
    echo -e "${CYAN}╠══════════════════════════════════════════════════════════════╣${NC}"
    echo -e "${CYAN}║${NC} Test Files Found: ${GREEN}$total_test_files${NC}"
    echo -e "${CYAN}║${NC}   - tests/ directory: ${GREEN}$test_files${NC}"
    echo -e "${CYAN}║${NC}   - root directory: ${GREEN}$root_test_files${NC}"
    echo -e "${CYAN}║${NC}   - streaming tests: ${GREEN}$streaming_test_files${NC}"
    echo -e "${CYAN}║${NC}"
    echo -e "${CYAN}║${NC} Reports Directory: ${GREEN}$REPORTS_DIR${NC}"
    echo -e "${CYAN}║${NC} Coverage Directory: ${GREEN}$COVERAGE_DIR${NC}"
    echo -e "${CYAN}║${NC} Timestamp: ${GREEN}$TIMESTAMP${NC}"
    echo -e "${CYAN}╚══════════════════════════════════════════════════════════════╝${NC}"
    echo ""
}

# Function to open reports
open_reports() {
    print_status "Opening test reports..."
    
    # Open HTML reports
    if [ -d "$REPORTS_DIR" ]; then
        local html_reports=$(find "$REPORTS_DIR" -name "*.html" | head -1)
        if [ -n "$html_reports" ]; then
            print_success "Opening HTML report: $html_reports"
            if command_exists open; then
                open "$html_reports"
            elif command_exists xdg-open; then
                xdg-open "$html_reports"
            else
                print_warning "Cannot open HTML report automatically"
            fi
        fi
    fi
    
    # Open coverage reports
    if [ -d "$COVERAGE_DIR" ]; then
        local coverage_reports=$(find "$COVERAGE_DIR" -name "index.html" | head -1)
        if [ -n "$coverage_reports" ]; then
            print_success "Opening coverage report: $coverage_reports"
            if command_exists open; then
                open "$coverage_reports"
            elif command_exists xdg-open; then
                xdg-open "$coverage_reports"
            else
                print_warning "Cannot open coverage report automatically"
            fi
        fi
    fi
}

# Main execution
main() {
    # Parse command line arguments
    local test_suite="all"
    local install_deps=false
    local clean=false
    local open_reports=false
    local skip_deps=false
    local keyword=""
    local marker=""
    local streaming_only=false
    local regression_only=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -v|--verbose)
                PYTEST_ARGS="$PYTEST_ARGS -v"
                shift
                ;;
            -c|--coverage)
                PYTEST_ARGS="$PYTEST_ARGS --cov=. --cov-report=term-missing"
                shift
                ;;
            -f|--fast)
                PYTEST_ARGS="$PYTEST_ARGS -q"
                shift
                ;;
            -k|--keyword)
                keyword="$2"
                PYTEST_ARGS="$PYTEST_ARGS -k $keyword"
                shift 2
                ;;
            -m|--marker)
                marker="$2"
                PYTEST_ARGS="$PYTEST_ARGS -m $marker"
                shift 2
                ;;
            -x|--stop-on-fail)
                PYTEST_ARGS="$PYTEST_ARGS -x"
                shift
                ;;
            --install-deps)
                install_deps=true
                shift
                ;;
            --clean)
                clean=true
                shift
                ;;
            --parallel)
                PYTEST_ARGS="$PYTEST_ARGS -n auto"
                shift
                ;;
            --html)
                PYTEST_ARGS="$PYTEST_ARGS --html"
                shift
                ;;
            --xml)
                PYTEST_ARGS="$PYTEST_ARGS --junitxml"
                shift
                ;;
            --open-reports)
                open_reports=true
                shift
                ;;
            --skip-deps)
                skip_deps=true
                shift
                ;;
            --streaming)
                streaming_only=true
                shift
                ;;
            --regression)
                regression_only=true
                shift
                ;;
            *)
                print_error "Unknown option: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    # Install dependencies if requested
    if [ "$install_deps" = true ]; then
        install_dependencies
        exit 0
    fi
    
    # Clean artifacts if requested
    if [ "$clean" = true ]; then
        clean_artifacts
        exit 0
    fi
    
    # Check Python environment
    check_python_environment
    
    # Check and install dependencies (unless skipped)
    if [ "$skip_deps" = false ]; then
        check_and_install_dependencies
    else
        print_warning "Skipping dependency checks (--skip-deps)"
        print_status "Make sure all required dependencies are installed"
    fi
    
    # Generate summary
    generate_summary
    
    # Run tests
    local test_success=true
    
    if [ "$streaming_only" = true ]; then
        test_suite="streaming"
    elif [ "$regression_only" = true ]; then
        test_suite="regression"
    elif [ -n "$keyword" ]; then
        test_suite="keyword_$keyword"
    elif [ -n "$marker" ]; then
        test_suite="marker_$marker"
    fi
    
    if ! run_unit_tests "$test_suite"; then
        test_success=false
    fi
    
    # Open reports if requested
    if [ "$open_reports" = true ]; then
        open_reports
    fi
    
    # Display results
    echo ""
    echo -e "${CYAN}╔══════════════════════════════════════════════════════════════╗${NC}"
    echo -e "${CYAN}║                    Test Execution Complete                   ║${NC}"
    echo -e "${CYAN}╠══════════════════════════════════════════════════════════════╣${NC}"
    
    if [ "$test_success" = true ]; then
        echo -e "${CYAN}║${NC} Status: ${GREEN}✅ ALL TESTS PASSED${NC}"
        echo -e "${CYAN}║${NC} Result: ${GREEN}SUCCESS${NC}"
    else
        echo -e "${CYAN}║${NC} Status: ${RED}❌ SOME TESTS FAILED${NC}"
        echo -e "${CYAN}║${NC} Result: ${RED}FAILURE${NC}"
    fi
    
    echo -e "${CYAN}║${NC}"
    echo -e "${CYAN}║${NC} Reports: ${GREEN}$REPORTS_DIR${NC}"
    echo -e "${CYAN}║${NC} Coverage: ${GREEN}$COVERAGE_DIR${NC}"
    echo -e "${CYAN}╚══════════════════════════════════════════════════════════════╝${NC}"
    echo ""
    
    # Exit with appropriate code
    if [ "$test_success" = true ]; then
        exit 0
    else
        exit 1
    fi
}

# Run main function with all arguments
main "$@"
