#!/bin/bash

# Mini RAG API Testing Script with Newman
# This script runs the Postman collection using Newman CLI
# and generates comprehensive test reports

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
COLLECTION_FILE="tests/integration/postman/collection.json"
ENVIRONMENT_FILE="tests/integration/postman/environment.json"
REPORTS_DIR="test-reports"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
REPORT_PREFIX="mini-rag-test"

# Function to print colored output
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "${PURPLE}[HEADER]${NC} $1"
}

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check if service is running
check_service() {
    local url=$1
    local service_name=$2
    
    if curl -s "$url" >/dev/null 2>&1; then
        print_success "$service_name is running"
        return 0
    else
        print_error "$service_name is not running at $url"
        return 1
    fi
}

# Function to wait for service to be ready
wait_for_service() {
    local url=$1
    local service_name=$2
    local max_attempts=30
    local attempt=1
    
    print_status "Waiting for $service_name to be ready..."
    
    while [ $attempt -le $max_attempts ]; do
        if curl -s "$url" >/dev/null 2>&1; then
            print_success "$service_name is ready!"
            return 0
        fi
        
        echo -n "."
        sleep 2
        attempt=$((attempt + 1))
    done
    
    print_error "$service_name failed to start within expected time"
    return 1
}

# Function to confirm action
confirm() {
    local message=$1
    echo -n "$message (y/N): "
    read -r response
    case "$response" in
        [yY][eE][sS]|[yY])
            return 0
            ;;
        *)
            return 1
            ;;
    esac
}

# Function to install Newman if not present
install_newman() {
    print_status "Installing Newman CLI..."
    if command_exists npm; then
        npm install -g newman
        print_success "Newman installed successfully"
    else
        print_error "npm is not installed. Please install Node.js and npm first."
        print_status "Alternative installation methods:"
        echo "  1. Install Node.js from https://nodejs.org/"
        echo "  2. Or use: curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash"
        echo "  3. Then: nvm install node && npm install -g newman"
        exit 1
    fi
}

# Function to install Newman reporters
install_reporters() {
    print_status "Installing Newman reporters..."
    npm install -g newman-reporter-htmlextra
    print_success "Newman reporters installed successfully"
}

# Function to create test files for upload testing
create_test_files() {
    print_status "Creating test files for upload testing..."
    
    # Create reports directory if it doesn't exist
    mkdir -p "$REPORTS_DIR"
    
    # Generate timestamp for unique filenames
    local file_timestamp=$(date +"%Y%m%d_%H%M%S")
    
    # Create test markdown file
    local test_md_file="$REPORTS_DIR/test_document_${file_timestamp}.md"
    
    cat > "$test_md_file" << 'EOF'
# Test Document for Mini RAG API

This is a test document created for testing the Mini RAG API file upload functionality.

## Content

This document contains sample content to test the document indexing and question answering capabilities of the Mini RAG system.

### Key Features

- Document indexing
- Question answering
- File upload support
- Text processing

### Sample Questions

You can ask questions like:
- What is this document about?
- What are the key features mentioned?
- What can you tell me about the Mini RAG system?

### Technical Details

This document is created automatically by the test script to ensure proper testing of the file upload functionality.
EOF

    # Create a simple text file as well
    local test_txt_file="$REPORTS_DIR/test_text_${file_timestamp}.txt"
    cat > "$test_txt_file" << EOF
This is a simple text file for testing purposes.
Created on: $(date)
File type: Plain text
Purpose: Testing file upload functionality
Content: Sample text for Mini RAG API testing
EOF

    # Create a JSON file for testing
    local test_json_file="$REPORTS_DIR/test_data_${file_timestamp}.json"
    cat > "$test_json_file" << EOF
{
  "title": "Test Data File",
  "description": "This is a test JSON file for the Mini RAG API",
  "created": "$(date -Iseconds)",
  "content": {
    "type": "test",
    "purpose": "file upload testing",
    "features": [
      "document indexing",
      "question answering",
      "file processing"
    ]
  }
}
EOF

    # Create an unsupported file type for testing
    local test_unsupported_file="$REPORTS_DIR/test_unsupported_${file_timestamp}.xyz"
    cat > "$test_unsupported_file" << EOF
This is a test file with unsupported extension (.xyz)
Created on: $(date)
Purpose: Testing unsupported file type handling
Content: This should trigger an "Unsupported extension" error
EOF

    print_success "Created test files:"
    echo "  - $test_md_file"
    echo "  - $test_txt_file"
    echo "  - $test_json_file"
    echo "  - $test_unsupported_file"
    
    # Export file paths for use in Postman environment
    echo "export TEST_MD_FILE=\"$test_md_file\"" > "$REPORTS_DIR/test_files.env"
    echo "export TEST_TXT_FILE=\"$test_txt_file\"" >> "$REPORTS_DIR/test_files.env"
    echo "export TEST_JSON_FILE=\"$test_json_file\"" >> "$REPORTS_DIR/test_files.env"
    echo "export TEST_UNSUPPORTED_FILE=\"$test_unsupported_file\"" >> "$REPORTS_DIR/test_files.env"
    
    # Update environment file with test file paths
    if [ -f "$ENVIRONMENT_FILE" ]; then
        # Create a backup of the original environment file
        cp "$ENVIRONMENT_FILE" "$ENVIRONMENT_FILE.backup"
        
        # Add test file variables to environment
        jq --arg md_file "$test_md_file" --arg txt_file "$test_txt_file" --arg json_file "$test_json_file" --arg unsupported_file "$test_unsupported_file" \
           '.values += [
               {"key": "test_md_file", "value": $md_file, "enabled": true},
               {"key": "test_txt_file", "value": $txt_file, "enabled": true},
               {"key": "test_json_file", "value": $json_file, "enabled": true},
               {"key": "test_unsupported_file", "value": $unsupported_file, "enabled": true}
           ]' "$ENVIRONMENT_FILE.backup" > "$ENVIRONMENT_FILE"
        
        print_success "Updated environment file with test file paths"
    fi
    
    print_success "Test files created and environment updated successfully!"
}


# Function to run tests with different configurations
run_tests() {
    local test_name=$1
    local collection_file=$2
    local environment_file=$3
    local output_suffix=$4
    local additional_args=$5
    
    print_header "Running $test_name tests..."
    
    # Create reports directory
    mkdir -p "$REPORTS_DIR"
    
    # Define report file names - single comprehensive report
    local html_report="$REPORTS_DIR/${REPORT_PREFIX}_${output_suffix}_${TIMESTAMP}.html"
    local json_report="$REPORTS_DIR/${REPORT_PREFIX}_${output_suffix}_${TIMESTAMP}.json"
    local xml_report="$REPORTS_DIR/${REPORT_PREFIX}_${output_suffix}_${TIMESTAMP}.xml"
    
    # Simple Newman command
    local newman_cmd="newman run \"$collection_file\" -e \"$environment_file\" --reporters=cli,htmlextra"
    
    # Add additional arguments if provided
    if [ -n "$additional_args" ]; then
        newman_cmd="$newman_cmd $additional_args"
    fi
    
    # Run the tests
    print_status "Executing Newman tests for: $test_name"
    echo ""
    
    # Execute the command and capture exit code
    local exit_code=0
    if eval $newman_cmd; then
        print_success "$test_name tests completed successfully"
        exit_code=0
    else
        print_error "$test_name tests failed"
        exit_code=1
    fi
    
    # Check if Newman generated any reports
    print_status "Newman test execution completed"
    
    return $exit_code
}


# Function to generate summary report
generate_summary() {
    print_status "Test execution completed - check Newman output above for results"
}

# Function to open HTML reports in browser
open_html_reports() {
    print_status "HTML reports are generated by Newman - check the output above for file locations"
}

# Function to display help
show_help() {
    echo "Mini RAG API Testing Script with Newman"
    echo ""
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  --help, -h          Show this help message"
    echo "  --suite SUITE       Run specific test suite (auth, rag, health, streaming, all)"
    echo "  --verbose, -v       Enable verbose output"
    echo "  --skip-checks       Skip service availability checks"
    echo "  --install-deps      Install Newman and reporters"
    echo "  --summary-only      Generate summary report only"
    echo "  --open-reports      Open HTML reports in browser after testing"
    echo "  --streaming         Run only streaming-related tests"
    echo "  --regression        Run only regression tests for streaming"
    echo ""
    echo "Examples:"
    echo "  $0                  # Run all tests with full checks"
    echo "  $0 --suite auth     # Run only authentication tests"
    echo "  $0 --suite streaming # Run only streaming tests"
    echo "  $0 --streaming      # Run only streaming-related tests"
    echo "  $0 --regression     # Run only regression tests for streaming"
    echo "  $0 --verbose        # Run with detailed output"
    echo "  $0 --skip-checks    # Run without checking if services are up"
    echo ""
}

# Main function
main() {
    echo -e "${CYAN}"
    echo "╔══════════════════════════════════════════════════════════════╗"
    echo "║                Mini RAG API Testing Suite                   ║"
    echo "║                    Powered by Newman                        ║"
    echo "╚══════════════════════════════════════════════════════════════╝"
    echo -e "${NC}"
    
    # Parse command line arguments
    local suite="all"
    local verbose=false
    local skip_checks=false
    local install_deps=false
    local summary_only=false
    local open_reports=false
    local streaming_only=false
    local regression_only=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --help|-h)
                show_help
                exit 0
                ;;
            --suite)
                suite="$2"
                shift 2
                ;;
            --verbose|-v)
                verbose=true
                shift
                ;;
            --skip-checks)
                skip_checks=true
                shift
                ;;
            --install-deps)
                install_deps=true
                shift
                ;;
            --summary-only)
                summary_only=true
                shift
                ;;
            --open-reports)
                open_reports=true
                shift
                ;;
            --streaming)
                streaming_only=true
                shift
                ;;
            --regression)
                regression_only=true
                shift
                ;;
            *)
                print_error "Unknown option: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    # Install dependencies if requested
    if [ "$install_deps" = true ]; then
        install_newman
        install_reporters
        exit 0
    fi
    
    # Check if Newman is installed
    if ! command_exists newman; then
        print_warning "Newman is not installed"
        if confirm "Install Newman CLI now?"; then
            install_newman
            install_reporters
        else
            print_error "Cannot proceed without Newman. Please install it manually."
            exit 1
        fi
    fi
    
    # Check if collection and environment files exist
    if [ ! -f "$COLLECTION_FILE" ]; then
        print_error "Collection file not found: $COLLECTION_FILE"
        exit 1
    fi
    
    if [ ! -f "$ENVIRONMENT_FILE" ]; then
        print_error "Environment file not found: $ENVIRONMENT_FILE"
        exit 1
    fi
    
    print_success "Collection and environment files found"
    
    # Check service availability unless skipped
    if [ "$skip_checks" = false ]; then
        print_status "Checking service availability..."
        
        if ! check_service "http://localhost:8000/health" "RAG API"; then
            print_warning "RAG API is not running"
            print_status "Please start the RAG API first:"
            echo "  • Using Docker: ./start-docker.sh"
            echo "  • Using local: ./start.sh && uvicorn app:app --host 0.0.0.0 --port 8000"
            echo ""
            if ! confirm "Continue with tests anyway?"; then
                exit 1
            fi
        fi
    fi
    
    # Generate summary only if requested
    if [ "$summary_only" = true ]; then
        generate_summary
        exit 0
    fi
    
    # Create test files for upload testing
    create_test_files
    
    # Run tests based on suite selection
    local test_success=true
    
    # Handle streaming-specific options
    if [ "$streaming_only" = true ]; then
        suite="streaming"
    elif [ "$regression_only" = true ]; then
        suite="regression"
    fi
    
    case $suite in
        "auth")
            run_tests "Authentication" "$COLLECTION_FILE" "$ENVIRONMENT_FILE" "auth" "--folder 'Authentication'"
            ;;
        "rag")
            run_tests "RAG Operations" "$COLLECTION_FILE" "$ENVIRONMENT_FILE" "rag" "--folder 'RAG Operations'"
            ;;
        "health")
            run_tests "Health Check" "$COLLECTION_FILE" "$ENVIRONMENT_FILE" "health" "--folder 'Health Check'"
            ;;
        "streaming")
            print_header "Running streaming-specific tests..."
            run_tests "Streaming Tests" "$COLLECTION_FILE" "$ENVIRONMENT_FILE" "streaming" "--folder 'Questions'"
            ;;
        "regression")
            print_header "Running streaming regression tests..."
            run_tests "Streaming Regression Tests" "$COLLECTION_FILE" "$ENVIRONMENT_FILE" "regression" "--folder 'Streaming Regression Tests'"
            ;;
        "all"|*)
            print_header "Running comprehensive test suite with organized scenarios..."
            
            # Run all tests in one comprehensive report with organized folders
            if ! run_tests "Complete Suite with Scenarios" "$COLLECTION_FILE" "$ENVIRONMENT_FILE" "complete"; then
                test_success=false
            fi
            ;;
    esac
    
    # Generate summary report
    generate_summary
    
    # Open HTML reports if requested
    if [ "$open_reports" = true ]; then
        open_html_reports
    fi
    
    # Display results
    echo ""
    echo -e "${CYAN}╔══════════════════════════════════════════════════════════════╗${NC}"
    if [ "$test_success" = true ]; then
        echo -e "${CYAN}║                    🎉 Tests Completed! 🎉                    ║${NC}"
    else
        echo -e "${CYAN}║                    ⚠️  Tests Completed with Issues ⚠️        ║${NC}"
    fi
    echo -e "${CYAN}╚══════════════════════════════════════════════════════════════╝${NC}"
    echo ""
    
    print_status "Test execution completed"
    print_status "Check Newman output above for test results"
    echo ""
    echo ""
    
    if [ "$test_success" = true ]; then
        print_success "All tests passed successfully!"
        exit 0
    else
        print_warning "Some tests failed. Check the reports for details."
        exit 1
    fi
}

# Handle script interruption
trap 'echo -e "\n${YELLOW}[WARNING]${NC} Testing interrupted"; exit 1' INT TERM

# Run main function
main "$@"
